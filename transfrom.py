
import pandas as pd
import json
import os
import csv

# This script was auto-generated by the Smart Data Mapper.
# It transforms data from a source file to a target structure based on a mapping configuration.

def load_source_data(file_path: str) -> pd.DataFrame:
    """Loads a DataFrame from a CSV, JSON, or XML file, detecting the format."""
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Error: The file '{file_path}' was not found.")
    
    _, file_extension = os.path.splitext(file_path)
    
    try:
        if file_extension.lower() == '.csv':
            with open(file_path, 'r', encoding='utf-8-sig') as f:
                try:
                    dialect = csv.Sniffer().sniff(f.read(2048))
                    delimiter = dialect.delimiter
                except csv.Error:
                    delimiter = ','
            return pd.read_csv(file_path, delimiter=delimiter)
        elif file_extension.lower() == '.json':
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return pd.json_normalize(data)
        elif file_extension.lower() == '.xml':
            try:
                return pd.read_xml(file_path)
            except ImportError:
                raise ImportError("Reading XML files requires the 'lxml' library. Please install it using 'pip install lxml'.")
        else:
            print(f"Warning: Unknown file type '{file_extension}'. Attempting to read as CSV.")
            return pd.read_csv(file_path)
    except Exception as e:
        raise IOError(f"Error reading or parsing file '{file_path}': {e}")

def set_nested_value(record: dict, path: str, value):
    """Sets a value in a nested dictionary based on a dot-separated path."""
    keys = path.split('.')
    d = record
    for key in keys[:-1]:
        d = d.setdefault(key, {})
    d[keys[-1]] = value

def transform_data(source_df: pd.DataFrame, mappings: list) -> list:
    """Transforms the source DataFrame into a list of target records."""
    target_records = []
    for _, source_row in source_df.iterrows():
        target_record = {}
        for mapping in mappings:
            source_field = mapping['source_field']
            target_path = mapping['target_field']
            
            if source_field in source_row and pd.notna(source_row[source_field]):
                value = source_row[source_field]
                # TODO: Add data type conversions here based on mapping details
                set_nested_value(target_record, target_path, value)
        
        target_records.append(target_record)
        
    return target_records

def main():
    # --- Configuration ---
    SOURCE_FILE = r'/home/drawnparadox/smartDataMapper/sap_idoc_sample.xml'
    MAPPINGS_FILE = r'/home/drawnparadox/smartDataMapper/recommended_mappings.json'
    OUTPUT_FILE = 'transformed_data.json' # You can change this
    # ---------------------

    print(f"1. Loading mappings from {MAPPINGS_FILE}")
    with open(MAPPINGS_FILE, 'r', encoding='utf-8') as f:
        mapping_data = json.load(f)
    mappings = mapping_data.get('recommended_mappings', [])

    print(f"2. Loading source data from {SOURCE_FILE}")
    source_df = load_source_data(SOURCE_FILE)

    print("3. Transforming data...")
    target_records = transform_data(source_df, mappings)

    print(f"4. Saving transformed data to {OUTPUT_FILE}")
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(target_records, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… Transformation complete. Output saved to {OUTPUT_FILE}.")

if __name__ == "__main__":
    main()
